estimates2013 <- select(estimates2013,covariate_id,covariate_name_short,location_id,year_id,age_group_id,sex_id,mean_value)
#estimates2013 <- rename(estimates2013, mean2013 = mean_value)
names(estimates2013)[names(estimates2013) == "mean_value"] <- 'mean2013'
#get GBD 2015 estimates
estimates2015 <- get_estimates_2015(covariate_name_short)
estimates2015 <- unique(estimates2015)
estimates2015 <- select(estimates2015,covariate_id,covariate_name_short,location_id,year_id, ihme_loc_id,age_group_id, age_group_name, sex_id,mean_value, location_name, region_name)
names(estimates2015)[names(estimates2015) == "mean_value"] <- 'mean2015'
#merge 2013 amd 2015 estimates
estimates <- merge(estimates2013, estimates2015, by=c("covariate_id","location_id","year_id","sex_id","age_group_id","covariate_name_short"), all.x = TRUE)
estimates <- unique(na.omit(estimates))
#plot formatting
y_mod_lab <- "Active best model"
x_mod_lab <- "GBD 2013 best model"
estimates$mean2013[is.na(estimates$mean2013)] <- 0
estimates$mean2015[is.na(estimates$mean2015)] <- 0
estimates$sex <- ifelse(estimates$sex_id == 1, "Male",ifelse(estimates$sex_id == 2,"Female", "Both Sex"))
estimates$sex <- factor(estimates$sex, levels = c("Male", "Female", "Both Sex"))
estimates$age_group_name <- factor(estimates$age_group_name)
#    if (!any(estimates$sex_id %in% c(1,2))) {
#       estimates$sex <- "Both Sex"
#    }
#set regions for color coding
gnum <- 21
gname <- "Region"
#find the range of mean values for 2013 and 2015
estimates$region_name <- factor(estimates$region_name, levels = c("High-income Asia Pacific","Western Europe","High-income North America","Australasia","Southern Latin America",
"Central Europe","Eastern Europe","Central Asia",
"Central Sub-Saharan Africa","Eastern Sub-Saharan Africa","Southern Sub-Saharan Africa","Western Sub-Saharan Africa",
"North Africa and Middle East",
"South Asia",
"East Asia","Southeast Asia","Oceania",
"Andean Latin America","Central Latin America","Tropical Latin America","Caribbean"))
col_grad <- colorRampPalette(c("#9E0142", "#F46D43", "#FEE08B", "#E6F598", "#66C2A5", "#5E4FA2"), space = "rgb")
#one plot for each year to same pdf
#years <- c(1990,1995,2000,2005,2010,2015)
#ifelse(!dir.exists(file.path(mainDir)), dir.create(file.path(mainDir)), FALSE)
#                 for (sx in unique(estimates$sex)) {
#                         print(paste(year, "_", sx))
estimate_by_year_sex <- unique(filter(estimates, year_id == year))
graph_title <- paste0(covariate_name_short, ": ",year)
rng_2013 <- range(estimates$mean2013)
rng_2015 <- range(estimates$mean2015)
model_plot <- ggplot(data=estimate_by_year_sex, aes(x=mean2013, y=mean2015, color=region_name)) +
geom_point() +
geom_text(aes(label=ihme_loc_id), hjust=.5, vjust=.5,show.legend = F) +
scale_y_continuous() +
scale_colour_manual(values=rev(col_grad(gnum)), name=gname) +
xlab(paste0(x_mod_lab,"")) +
ylab(paste0(y_mod_lab,"")) +
coord_cartesian(ylim=rng_2015, xlim=rng_2013) +
facet_grid(sex~age_group_name) +
geom_abline(data=estimate_by_year_sex, intercept = 0, slope = 1, colour="black") +
ggtitle(graph_title) +
theme_bw()+
theme(axis.title.x = element_text(face="bold", color="black", size=14),
axis.title.y = element_text(face="bold", color="black", size=14),
axis.text.x = element_text(color="black", size=12),
axis.text.y = element_text(color="black", size=12),
plot.title = element_text(face="bold", color = "black", size=16),
legend.position="bottom")
#print(model_plot, width=800,height=700)
dev.off()
}
#get the list of covariates
covariates <- as.list(get_covariates()$covariate_name_short)
#Set the GBD years
years <- c(1990,1995,2000,2005,2010,2015)
#create a server function
shinyServer(function(input, output) {
#Choose the covariate of interest to be vetted
datasetInput <- reactive({
switch(input$covariate,
"covariates"= covariates)
})
#         sexInput <- reactive({
#                 switch(input$sex,
#                        "covariates"= sexes)
#
#         })
yearInput <- reactive({
switch(input$year,
"years"=years)
})
#create plot
output$scatter <- renderPlot({
covariate_scatter(input$covariate,input$year)
})
})
runApp()
runApp()
runApp()
setwd("~/COURSERA/data_products/slidify_practice")
#load required libraries
pacman::p_load(dplyr,funModeling,caret,data.table,rpart,randomForest,rattle, ggplot2)
#--------------------------------- DATA PRE-PROCESSING -----------------------------------------------------------
#import the data
download.file("https://www.huduser.gov/portal/datasets/hads/hads2013n_ASCII.zip", destfile = "housing_data.zip")
#unzip file
unzip("housing_data.zip")
#read the data
data <- read.table("thads2013n.txt", sep = ",", header = TRUE)
#rename variables to lower case
names(data) <- tolower(names(data))
#change data frame to a data table
data <- as.data.table(data)
View(data)
x <- filter(data, built == 2009)
View(x)
x <- filter(data, built == 2008)
View(x)
max(data$built)
unique(data$built)
x <- filter(data, built >= 2012)
x <- filter(data, built >= 2011)
x <- filter(data, built >= 2010)
download.file("https://www.huduser.gov/portal/datasets/hads/hads2013n_ASCII.zip", destfile = "housing_data.zip")
#unzip file
unzip("housing_data.zip")
#read the data
data <- read.table("thads2013n.txt", sep = ",", header = TRUE)
#rename variables to lower case
names(data) <- tolower(names(data))
#change data frame to a data table and subset to get houses built post 2009
data <- as.data.table(data) %>% filter(built >= 2010)
#select variables of interest
dt <- select(data, costmed, totsal, bedrms, age1)
#remove values that are zero or less than zero
dt <- dt[(apply(dt, 1, function(x) all(x > 0)))]
View(dt)
dt[, scale_cost := costmed * 12]
dt_status <- df_status(dt)
#Partition the training data into train and test sets
inTrain <- createDataPartition(y=dt$scale_cost, p=0.6, list=FALSE)
trainset<- dt[inTrain,]; testset <- dt[-inTrain,]
rfFit <- train(scale_cost~.,data=trainset, method="rf",prox=TRUE)
summary(rfFit)
rfFit
getTree(rfFit$finalModel, k=2)
importance(rfFit)
varImp(rfFit)
View(dt)
rpFit <- train(scale_cost~.,data=trainset, method="rpart")
print(rpFit$finalModdel)
print(rpFit$finalModel)
rpFit
gbmFit <- train(scale_cost~.,data=trainset, method="gbm")
gbmFit
names(gbmFit)
rpFit
min(gbmFit$RMSE))
plot(rpFit)
plot(gbmFit)
plot(rfFit)
rfFit
pacman::p_load(dplyr,funModeling,caret,data.table,rpart,randomForest,rattle, ggplot2, gridExtra)
?grid
?gridExtra
grid.arrange(rp.plot.rf.plot,gbm.plot)
grid.arrange(rp.plot,rf.plot,gbm.plot)
rp.plot <- plot(rpFit)
rf.plot <- plot(rfFit)
gbm.plot <- plot(gbmFit)
grid.arrange(rp.plot,rf.plot,gbm.plot)
str(rpfIT)
str(rpFit)
min(gbmFit$results$RMSE))
rmse <- c(min(rpFit$results$RMSE),
min(rfFit$results$RMSE),
min(gbmFit$results$RMSE))
rmse
rsquared <- c(max(rpFit$results$Rsquared),
max(rfFit$results$Rsquared),
max(gbmFit$results$Rsquared))
performance <- bind_cols(model, rmse, rsquared)
model <- c("Recursive Part Reg Trees","Random Forest","Generalized Boosted Model")
performance <- bind_cols(model, rmse, rsquared)
performance <- cbind(model, rmse, rsquared)
View(performance)
str(performance)
performance <- data.frame(model, rmse, rsquared)
View(performance)
pred <- predict(rfFit, testset)
testset$pred <- predict(rfFit, testset)
View(testset)
p <- ggplot(testest, scale_cost, pred) + geom_smmoth()
p <- ggplot(testset, scale_cost, pred) + geom_smmoth()
p <- ggplot(testset, scale_cost, pred) + geom_smmoth()
p <- ggplot(testset, aes(scale_cost, pred)) + geom_ponit() + abline
p <- ggplot(testset, aes(scale_cost, pred)) + geom_poin() + abline
p <- ggplot(testset, aes(scale_cost, pred)) + geom_point() + abline
p <- ggplot(testset, aes(scale_cost, pred)) + geom_point()
p
p <- ggplot(testset, aes(scale_cost, pred)) + geom_point() + geom_abline(0,1)
p <- ggplot(testset, aes(scale_cost, pred)) + geom_point() + geom_abline(intercept = 0, slope = 1)
p
?geom_abline
p <- ggplot(testset, aes(scale_cost, pred)) + geom_point() + geom_abline(intercept = 0, slope = 1, color = "orange")
p
p <- ggplot(testset, aes(scale_cost, pred)) + geom_point() + geom_abline(intercept = 0, slope = 1, color = "orange", size = 2)
p
p <- ggplot(testset, aes(scale_cost, pred)) + geom_point() + geom_abline(intercept = 0, slope = 1, color = "orange", size = 2) + theme_bw()
p
p <- ggplot(testset, aes(scale_cost, pred)) + geom_point(color="cadetblue", size=2) + geom_abline(intercept = 0, slope = 1, color = "orange", size = 2) + theme_bw()
p
#make a scatter plot comparing observed and predicted outcome
p <- ggplot(testset, aes(scale_cost, pred)) + geom_point((color="cadetblue", size=2)
p <- p + geom_abline(intercept = 0, slope = 1, color = "orange", size = 1.5)
p <- p + xlab("Obesrved Housing Cost") + ylab("Predicted Housing Cost")
P <- P + ggtitle("Predicted vs Observed Housing Cost from a Random Forest model")
p <- ggplot(testset, aes(scale_cost, pred)) + geom_point((color="cadetblue", size=2)
p <- p + geom_abline(intercept = 0, slope = 1, color = "orange", size = 1.5)
p <- p + xlab("Obesrved Housing Cost") + ylab("Predicted Housing Cost")
p <- p + ggtitle("Predicted vs Observed Housing Cost from a Random Forest model")
p
p <- ggplot(testset, aes(scale_cost, pred)) + geom_point((color="cadetblue", size=2)
p <- p + geom_abline(intercept = 0, slope = 1, color = "orange", size = 1)
p <- p + xlab("Obesrved Housing Cost") + ylab("Predicted Housing Cost")
p <- p + ggtitle("Predicted vs Observed Housing Cost from a Random Forest model")
testset$pred <- predict(rfFit, testset)
#make a scatter plot comparing observed and predicted outcome
p <- ggplot(testset, aes(scale_cost, pred)) + geom_point(color="cadetblue", size=2)
p <- p + geom_abline(intercept = 0, slope = 1, color = "orange", size = 1)
p <- p + xlab("Obesrved Housing Cost") + ylab("Predicted Housing Cost")
p <- p + ggtitle("Predicted vs Observed Housing Cost from a Random Forest model")
p
p <- p + theme_bw()
p
testset$pred <- predict(rfFit, testset)
#make a scatter plot comparing observed and predicted outcome
p <- ggplot(testset, aes(scale_cost, pred)) + geom_point(color="cadetblue", size=2)
p <- p + geom_abline(intercept = 0, slope = 1, color = "orange", size = 1)
p <- p + xlab("Obesrved Housing Cost(year)") + ylab("Predicted Housing Cost(year)")
p <- p + ggtitle("Predicted vs Observed Housing Cost from a Random Forest model")
p <- p + theme_bw()
p
grid.arrange(rp.plot,rf.plot,gbm.plot)
View(dt)
pacman::p_load(dplyr,funModeling,caret,data.table,rpart,randomForest,rattle, ggplot2, gridExtra,shiny,DT)
#load required libraries
pacman::p_load(dplyr,funModeling,caret,data.table,rpart,randomForest,rattle, ggplot2, gridExtra,shiny,DT)
#import the data
download.file("https://www.huduser.gov/portal/datasets/hads/hads2013n_ASCII.zip", destfile = "housing_data.zip")
#unzip file
unzip("housing_data.zip")
#read the data
data <- read.table("thads2013n.txt", sep = ",", header = TRUE)
#rename variables to lower case
names(data) <- tolower(names(data))
#select variables of interest
data <- as.data.table(data) %>% select(costmed, totsal, bedrms, age1)
#scaling the housing cost to yearly cost for comparison prupose to yearly income
data[, scale_cost := costmed * 12]
#remove values that are zero or less than zero
data <- data[(apply(data, 1, function(x) all(x > 0)))]
dt <- data %>% filter(built >= 2010)
dt_status <- df_status(dt)
#-------------------------------------------------------------------
#Data product final project
#Purpose : Predicting Housing costs based on different predictors
#          including owner's age, income, and number of bedrooms in
#          the house
#Date : 4/19/2016
#Author :
#-------------------------------------------------------------------
#--------------------------------- DATA SUMMARY ------------------------------------------------------------------
#The data used id from the U.S department of Housing and Urban Development website. It's the Housing Affordability
#data derived from the American Housing Survey. More info can be found here
#https://www.huduser.gov/portal/datasets/hads/hads.html
#--------------------------------- DATA PRE-PROCESSING -----------------------------------------------------------
#load required libraries
pacman::p_load(dplyr,funModeling,caret,data.table,rpart,randomForest,rattle, ggplot2, gridExtra,shiny,DT)
#import the data
download.file("https://www.huduser.gov/portal/datasets/hads/hads2013n_ASCII.zip", destfile = "housing_data.zip")
#unzip file
unzip("housing_data.zip")
#read the data
data <- read.table("thads2013n.txt", sep = ",", header = TRUE)
#rename variables to lower case
names(data) <- tolower(names(data))
#select variables of interest
data <- as.data.table(data) %>% select(costmed, totsal, bedrms, age1, built)
View(data)
data[, scale_cost := costmed * 12]
View(data)
data <- data[(apply(data, 1, function(x) all(x > 0)))]
dt <- data %>% filter(built >= 2010)
testset2 <- filter(data, built %in% c(2007,2008,2009))
testset3 <- filter(data, built %in% c(2004,2005,2006))
testset5 <- filter(data, buikt %in% c(1985,1990,2000))
testset5 <- filter(data, built %in% c(1985,1990,2000))
View(performance)
getwd()
setwd("~/COURSERA/data_products")
#-------------------------------------------------------------------
#Data product final project
#Purpose : Predicting Housing costs based on different predictors
#          including owner's age, income, and number of bedrooms in
#          the house
#Date : 4/19/2016
#Author :
#-------------------------------------------------------------------
#--------------------------------- DATA SUMMARY ------------------------------------------------------------------
#The data used id from the U.S department of Housing and Urban Development website. It's the Housing Affordability
#data derived from the American Housing Survey. More info can be found here
#https://www.huduser.gov/portal/datasets/hads/hads.html
#--------------------------------- DATA PRE-PROCESSING -----------------------------------------------------------
#load required libraries
pacman::p_load(dplyr,funModeling,caret,data.table,rpart,randomForest,rattle, ggplot2, gridExtra,shiny,DT)
#import the data
download.file("https://www.huduser.gov/portal/datasets/hads/hads2013n_ASCII.zip", destfile = "housing_data.zip")
#unzip file
unzip("housing_data.zip")
#read the data
data <- read.table("thads2013n.txt", sep = ",", header = TRUE)
#rename variables to lower case
names(data) <- tolower(names(data))
#select variables of interest
data <- as.data.table(data) %>% select(costmed, totsal, bedrms, age1, built)
#scaling the housing cost to yearly cost for comparison prupose to yearly income
data[, scale_cost := costmed * 12]
#remove values that are zero or less than zero
data <- data[(apply(data, 1, function(x) all(x > 0)))]
#subset to get houses built post 2009
dt <- data %>% filter(built >= 2010)
#get the overall status of the data. The status resulted in a missing values free
#data. Alos no zero values in the data
dt_status <- df_status(dt)
#--------------------------------- DATA ANALYSIS --------------------------------------------------------------
#Partition the training data into train and test sets
inTrain <- createDataPartition(y=dt$scale_cost, p=0.6, list=FALSE)
trainset<- dt[inTrain,]; testset <- dt[-inTrain,]
#Fit models : trees, random forest and boosting
rpFit <- train(scale_cost~.,data=trainset, method="rpart")
rfFit <- train(scale_cost~.,data=trainset, method="rf",prox=TRUE)
gbmFit <- train(scale_cost~.,data=trainset, method="gbm")
#plot models
rp.plot <- plot(rpFit)
rf.plot <- plot(rfFit)
gbm.plot <- plot(gbmFit)
#clearly random forest preformed better with the lowest RMSE
diagplots <- grid.arrange(rp.plot,rf.plot,gbm.plot)
#concatenating the fitted models into a single vector
model <- c("Recursive Part Reg Trees","Random Forest","Generalized Boosted Model")
#Comparing the models to get the best fitted model
rmse <- c(min(rpFit$results$RMSE),
min(rfFit$results$RMSE),
min(gbmFit$results$RMSE))
rsquared <- c(max(rpFit$results$Rsquared),
max(rfFit$results$Rsquared),
max(gbmFit$results$Rsquared))
#gathering accuracy info into a data frame
performance <- data.frame(model, rmse, rsquared)
#get 5 test datasets from the original data
testset2 <- filter(data, built %in% c(2007,2008,2009))
testset3 <- filter(data, built %in% c(2004,2005,2006))
testset4 <- filter(data, built %in% c(2001,2002,2003))
testset5 <- filter(data, built %in% c(1985,1990,2000))
#--- SERVER
shinyServer(function(input, output) {
#input test dataset
datasetInput <- reactive({
switch(input$dataset,
"testset1"=testset,
"testset2"=testset2,
"testset3"=testset3,
"testset4"=testset4,
"testset5"=testset5)
})
#Generate a summary of measures of accuracy for 3 different models (RMSE and Rsquared)
output$summary <- DT::renderPrint({
performance
})
# customize the length drop-down menu; display 5 rows per page by default
output$plot <- DT::renderPlot({
test <- datasetInput()
#The random forest model is selected for prediction as it's the best
test$pred <- predict(rfFit, test)
#make a scatter plot comparing observed and predicted outcome
p <- ggplot(test, aes(scale_cost, pred)) + geom_point(color="cadetblue", size=2)
p <- p + geom_abline(intercept = 0, slope = 1, color = "orange", size = 1)
p <- p + xlab("Obesrved Housing Cost(year)") + ylab("Predicted Housing Cost(year)")
p <- p + ggtitle("Predicted vs Observed Housing Cost from a Random Forest model")
p <- p + theme_bw()
print(p)
})
#plot dignostics plots for models
output$diagnostics <- DT::renderPlot({
grid.arrange(rp.plot,rf.plot,gbm.plot)
})
})
library(shiny)
shinyUI(fluidPage(
titlePanel("Housing Cost Prediction"),
SidebarPanel(
# Setting id makes input$tabs give the tabName of currently-selected tab
selectInput("dataset", "Choose a test set:",
choices = c("testset1", "testset2", "testset3", "testset4", "testset5"))
),
mainPanel(
tabsetPanel(
tabPanel('summary', DT::verbatimOutput('summary')),
tabPanel('plot', DT::plotOutput('plot'))
),
)
)
)
library(shiny)
shinyUI(fluidPage(
titlePanel("Housing Cost Prediction"),
sidebarPanel(
# Setting id makes input$tabs give the tabName of currently-selected tab
selectInput("dataset", "Choose a test set:",
choices = c("testset1", "testset2", "testset3", "testset4", "testset5"))
),
mainPanel(
tabsetPanel(
tabPanel('summary', DT::verbatimOutput('summary')),
tabPanel('plot', DT::plotOutput('plot'))
),
)
))
library(shiny);
shinyUI(fluidPage(
titlePanel("Housing Cost Prediction"),
sidebarPanel(
# Setting id makes input$tabs give the tabName of currently-selected tab
selectInput("dataset", "Choose a test set:",
choices = c("testset1", "testset2", "testset3", "testset4", "testset5"))
),
mainPanel(
tabsetPanel(
tabPanel('summary', verbatimOutput('summary')),
tabPanel('plot', plotOutput('plot'))
),
)
))
library(shiny);
shinyUI(fluidPage(
titlePanel("Housing Cost Prediction"),
sidebarPanel(
# Setting id makes input$tabs give the tabName of currently-selected tab
selectInput("dataset", "Choose a test set:",
choices = c("testset1", "testset2", "testset3", "testset4", "testset5"))
),
mainPanel(
tabsetPanel(
tabPanel('summary', verbatimTextOutput('summary')),
tabPanel('plot', plotOutput('plot'))
),
)
))
?tabPanel
runApp()
shinyUI(fluidPage(
titlePanel("Housing Cost Prediction"),
sidebarLayout(
sidebarPanel(
# Setting id makes input$tabs give the tabName of currently-selected tab
selectInput("dataset", "Choose a test set:",
choices = c("testset1", "testset2", "testset3", "testset4", "testset5"))
),
mainPanel(
tabsetPanel(
tabPanel('summary', verbatimTextOutput('summary')),
tabPanel('plot', plotOutput('plot'))
),
)
)
))
library(shiny);
shinyUI(fluidPage(
titlePanel("Housing Cost Prediction"),
sidebarLayout(
sidebarPanel(
# Setting id makes input$tabs give the tabName of currently-selected tab
selectInput("dataset", "Choose a test set:",
choices = c("testset1", "testset2", "testset3", "testset4", "testset5"))
),
mainPanel(
tabsetPanel(
tabPanel('summary', verbatimTextOutput('summary')),
tabPanel('plot', plotOutput('plot'))
)
)
)
))
runApp()
library(shiny)
shinyUI(fluidPage(
titlePanel("Housing Cost Prediction"),
sidebarLayout(
sidebarPanel(
# Setting id makes input$tabs give the tabName of currently-selected tab
selectInput("dataset", "Choose a test set:",
choices = c("testset1", "testset2", "testset3", "testset4", "testset5"))
),
mainPanel(
tabsetPanel(
tabPanel('summary', verbatimTextOutput('summary')),
tabPanel('plot', plotOutput('plot'))
)
)
)
))
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
